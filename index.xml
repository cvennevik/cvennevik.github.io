<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Cecilie Vennevik's blog</title>
    <link>https://www.cvennevik.no/</link>
    <description>Recent posts on Cecilie Vennevik's blog</description>
    <language>en</language>
    <lastBuildDate>Fri, 14 Apr 2023 20:15:00 +0000</lastBuildDate>
    <atom:link href="https://www.cvennevik.no/index.xml" rel="self" type="application/rss+xml"/>
    <item>
      <title>Oops, I made code review painful</title>
      <link>https://www.cvennevik.no/post/oops-i-made-code-review-painful/</link>
      <pubDate>Fri, 14 Apr 2023 20:15:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/oops-i-made-code-review-painful/</guid>
      <description><![CDATA[<p>A few months ago I wrote <a href="https://www.cvennevik.no/post/code-reviews-are-overloaded/">a post</a> suggesting that you should limit your pull request reviews to their bare essentials, the &quot;bare essentials&quot; here meaning &quot;bugs and irreversible design decisions.&quot; I've had the chance to try doing this at work, and now I can share my findings with you:</p>
<p>Boy howdy, I do not enjoy this at all.</p>
]]></description>
      <content:encoded><![CDATA[<p>A few months ago I wrote <a href="https://www.cvennevik.no/post/code-reviews-are-overloaded/">a post</a> suggesting that you should limit your pull request reviews to their bare essentials, the &quot;bare essentials&quot; here meaning &quot;bugs and irreversible design decisions.&quot; I've had the chance to try doing this at work, and now I can share my findings with you:</p>
<p>Boy howdy, I do not enjoy this at all.</p>
<p>There is one critical issue I did not consider in my original post: whether or not the different parts of review were any enjoyable or engaging. As it turns out, by trimming out every &quot;non-essential&quot; concern from my reviews, I have trimmed away every bit of the activity that was somewhat enjoyable and engaging. My slimmed-down review process is fast, efficient, and insufferable.</p>
<p>Evaluating and discussing design choices, suggesting renames and refactorings, and taking the time to find and point out things I like - these were all things that engaged the parts of my brain that I enjoy using. It was inefficient and slow and occasionally tiring, but at the end of a review session, I was satisfied with my work.</p>
<p>Now, code reviews come in two variants: the small and easy ones that I can knock out quickly and get out of my sight, and the large and difficult ones that drain the soul out of me. 1000 line diffs used to be tough, multiple-hour review sessions where at the end I would be happy with my effort. This has been replaced with me stumbling away from the monitor trying to reawaken the parts of my brain that shut down halfway through after refusing to process any more of the code that I was jamming through my eye sockets.</p>
<p>At least there is a fun irony in all of happening because I made my reviews &quot;less demanding.&quot;</p>
<p>Now that I've subjected myself to my own suggested experiment, my feelings on pull requests reviews have cooled significantly. I do not want to do any more of these &quot;efficient&quot; reviews than I absolutely have to. Yet despite not enjoying it, I do not want to go back to the way I reviewed code before. Even if it is more bearable, it is still slow, inefficient and tiring.</p>
<p>Honestly, at this point, I just want to be subjected to as little code review possible, both as a reviewer and a author. This is something I am working on!</p>
<p>I'm a big fan of the <a href="https://martinfowler.com/articles/ship-show-ask.html">Ship / Show / Ask</a> model, which makes pull request reviews something authors explicitly opt into. To start pushing the needle away from &quot;ask for review on all changes all the time,&quot; I have asked for and received permission to merge low-risk changes without review. And if you haven't tried it before, let me tell you, being able to merge refactoring and test work straight into mainline feels so very freeing. I highly recommend it.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>A corner-cutter&#39;s confession</title>
      <link>https://www.cvennevik.no/post/a-corner-cutters-confession/</link>
      <pubDate>Thu, 09 Feb 2023 20:45:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/a-corner-cutters-confession/</guid>
      <description><![CDATA[<p>Listen. I know I should have done this one better.</p>
]]></description>
      <content:encoded><![CDATA[<p>Listen. I know I should have done this one better.</p>
<p>Yes, I didn't spend time improving the design before I went to work. I slotted my change right into the design that was already there. It fit okay! With some slight cruft, duplication, and clunky call chaining, but still! Don't look at me like that - even Kent Beck says &quot;making the change easy&quot; is the hard part, and my job is hard enough!</p>
<p>And yes, yes, I didn't write any tests first. I know it would have made my work easier, and refactoring less error-prone. And it would have helped me out in the design process. But I knew what I needed to do (mostly)! And I could just boot up the app and test it manually - it was familiar and convenient!</p>
<p>What's that? Did I write any tests after, then? Oh, no, I didn't do that either. I'd, uh, already tested all the use cases manually by the time I finished. It felt like a waste of time not to merge the work and move on. Yes, I have no cheap way of catching regressions now, I know, I know. Can we move on?</p>
<p>Because there's so much to move on to. I can't afford to feel like I'm slow. There's so many more things to do! Important things! Features! Stories! Bugs! <em>Pull requests!</em> The board is so long and the days are so short and <em>I need to do my part</em>.</p>
<p>...</p>
<p>I just... I know it's better to move slowly and deliberately. I know it's a matter of practice. And I know it relieves stress in the end.</p>
<p>But there's just so much code, so many loose threads, and so much work to do. I can only bear so much of it in my head.</p>
<p>Can you fault me for going along with the flow?</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>&#39;Technical debt&#39; is an incomplete model</title>
      <link>https://www.cvennevik.no/post/technical-debt-is-an-incomplete-model/</link>
      <pubDate>Sun, 05 Feb 2023 10:51:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/technical-debt-is-an-incomplete-model/</guid>
      <description><![CDATA[<p>We throw around the &quot;technical debt&quot; metaphor a lot in software development. On project after project, we experience the system becoming harder to change as we work on it. Rushed design decisions come back to bite us in the butt. Progress slows to a crawl. We say we have accrued a lot of &quot;technical debt.&quot;</p>
]]></description>
      <content:encoded><![CDATA[<p>We throw around the &quot;technical debt&quot; metaphor a lot in software development. On project after project, we experience the system becoming harder to change as we work on it. Rushed design decisions come back to bite us in the butt. Progress slows to a crawl. We say we have accrued a lot of &quot;technical debt.&quot;</p>
<p>The &quot;technical debt&quot; metaphor is used to explain that we accrue <em>design flaws</em> as we work. These design flaws make it harder to change the system - the more flaws we have, the more we &quot;pay interest&quot; in increased time and effort to make new changes. To make the system easier to change again, we need to &quot;pay down the debt&quot; by fixing the design flaws. If we do not keep our &quot;technical debt&quot; in check, we risk accumulating so many design flaws that it is no longer economic to develop the system any further - we hit &quot;technical bankruptcy.&quot;</p>
<p>While this is a useful model, I've come to find it insufficient. It frames &quot;cost of change&quot; as something developers harm by introducing design flaws, and repair by removing design flaws. It is centered on the negative case.</p>
<p>The lessons I have learned about managing cost of change from the Extreme Programming community clashes with this framing, because the &quot;technical debt&quot; metaphor does not support the possibility that the cost of change can go <em>down</em> as you add changes to your system.</p>
<p>Eric Evans touches on this phenomenon through the lens of &quot;supple design&quot;:</p>
<blockquote>
<p>To have a project accelerate as development proceeds - rather than get weighed down by its own legacy - demands a design that is a pleasure to work with, inviting to change. A supple design.</p>
<p>— Eric Evans, <em>Domain-Driven Design</em>, Chapter Ten: &quot;Supple Design&quot;</p>
</blockquote>
<p>Eric compares the system design to a leather jacket that is initially stiff, but over months of use becomes comfortable and flexible in the joints. Similarly, when you keep making changes to the design as you work with the system, the parts you repeatedly need to change will become flexible and easy to change, while the rest of the design stays simple and firm.</p>
<p>Another way this phenomenon emerges is through the &quot;evolutionary design&quot; strategy. By building your design in small increments, keeping it as simple as you can, and reflecting and improving on the design with each and every change, you can manage to reduce the cost of change as you expand your system.</p>
<p>When James Shore describes this design strategy in <em>The Art of Agile Development</em>, he gives the example of a JavaScript project he did for one of his screencasts. As he added more and more features related to networking, each feature took less and less time to implement - from 12 hours, to 6 hours, to 3 hours, to under an hour - despite the later features being no less intricate than the earlier ones!</p>
<p>By improving the design with each and every change, the design does not merely stay out of our way. The design <em>actively supports and enables new changes</em>. By keeping the design clean while extending it with more functionality, we can make the system do more and more things with less effort. The codebase becomes a precious asset that accelerates our development, speeding us up instead of slowing us down.</p>
<p>These ways of reducing the cost of change are ill described as &quot;paying down technical debt.&quot; Instead, it is more accurate to say we are <strong><em>building technical wealth</em></strong>.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>I am a social animal</title>
      <link>https://www.cvennevik.no/post/i-am-a-social-animal/</link>
      <pubDate>Sat, 04 Feb 2023 07:42:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/i-am-a-social-animal/</guid>
      <description><![CDATA[<p>I do not thrive alone at the computer. I do not thrive in peace and quiet. I do not thrive with a well-defined problem in front of me, with my headphones on, and a whole day ahead of me before I have to interact with another human.</p>
<p>I cope with it.</p>
]]></description>
      <content:encoded><![CDATA[<p>I do not thrive alone at the computer. I do not thrive in peace and quiet. I do not thrive with a well-defined problem in front of me, with my headphones on, and a whole day ahead of me before I have to interact with another human.</p>
<p>I cope with it.</p>
<p>I muster the energy I have for the day. I devise elaborate techniques to focus myself. I work pomodoros. I meditate. I put on white noise. I journal. I break the work down into little digestible steps.</p>
<p>And so I manage being alone.</p>
<p>Yet sometimes, all the efforts in the world are not enough. Sometimes, I require that precious fruit: Another human's attention.</p>
<p>I carefully leave the confines of my desk, and I slink around the office to see what I can scavenge. Could there be a quick little question somewhere? A second opinion? A clarification? Oh, lucky day, a full discussion!</p>
<p>On this morsel, I return to my seat-burrow and savor my prize. My back straightens. My mind clears. I have been sated enough to function, for now, until I next need to go foraging.</p>
<p><em>How I long for the revitalizing presence of another human's company.</em></p>
<p>Some days these little morsels are not enough. Some days, I am starved.</p>
<p>My eyes glaze over the monitor. My arms are heavy. My body cannot sustain itself on table scraps of human interaction. It howls for <strong><em>collaboration</em></strong>.</p>
<p>When I get up from my seat, and look around, I see other humans. Alone at their computer. In peace and quiet. Each with their own well-defined problem in front of them, with their headphones on, with no need to talk to another human.</p>
<p>The air in the office is still. And I would do well not to disturb it.</p>
<p>I sit back down in my seat. I look at the time.</p>
<p>It is winter, yet.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Enforcing advanced type constraints with class constructors in TypeScript</title>
      <link>https://www.cvennevik.no/post/type-constraints-with-class-constructors/</link>
      <pubDate>Fri, 20 Jan 2023 06:37:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/type-constraints-with-class-constructors/</guid>
      <description><![CDATA[<p>For those really hard-to-define types.</p>
]]></description>
      <content:encoded><![CDATA[<p>Frequently, when programming, I am working with data that I expect to follow a set of constraints.</p>
<ul>
<li>This parameter must be a string.</li>
<li>This return value cannot be null.</li>
<li>This object must have a username property.</li>
</ul>
<p>Constraints like these are typically common and easy to express in statically typed languages.</p>
<p>Sometimes (actually a lot of times) I am working with data that should follow stricter, more complicated constraints.</p>
<ul>
<li>This user-submitted application cannot have the <code>approvedTime</code> value set.</li>
<li>This username must be non-empty and cannot have special characters.</li>
<li>This <code>from</code> value must be before the <code>to</code> value.</li>
</ul>
<p>These constraints can be more tricky to express in a type definition, and I rarely see it attempted. Instead, I see functions either assume the data is valid, or run validation checks on the data that throw an error if it breaks a rule.</p>
<p>Following the advice of <em>&quot;parse, don't validate&quot;</em> (see <a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">the wonderful post by Alexis King</a>), I would rather that the type itself is able to enforce its own constraints. This guarantees and preserves the validity of the data as you pass it on to other functions, and reduces the risk of insufficient <em>and</em> redundant validation checks around your codebase.</p>
<p>With a few tricks, most constraints you can imagine can be enforced with a type definition. In this case, I'll be showing how to use <strong>classes</strong> to guarantee constraints on TypeScript data that simple <code>type</code> and <code>interface</code> declarations are unable to. (This technique also works in any statically typed language that supports classes.)</p>
<h2 id="the-technique">The technique</h2>
<ol>
<li>Define a class containing the values you want to wrap.</li>
<li>In the constructor, check for any constraints you are interested in.</li>
<li>Throw an error if any of the constructor checks fail.</li>
</ol>
<p>Key to this technique being widely applicable is that <strong>you are allowed to write class wrappers for single values.</strong> You incur some overhead for having to instantiate each value as a class, and having to access the instance's value to use it, but in return you can enforce any constraint you can imagine in its constructor. Make this tradeoff at your own discretion.</p>
<p>To illustrate the technique, I've spun up a few examples showing what you can do with it.</p>
<h2 id="a-palindrome-type">A palindrome type</h2>
<pre><code class="language-ts">class Palindrome {
    readonly value: string;

    constructor (value: string) {
        const reversedValue = value.split('').reverse().join('');
        if (value !== reversedValue) {
            throw new Error(`&quot;${value}&quot; is not a palindrome`);
        }

        this.value = value;
    }
}
</code></pre>
<p>To ensure the string is a palindrome, we reverse it and check if the reversed string is equal to the original string. If not, we throw an error. Then we save the string to the <code>value</code> field.</p>
<p>In practice, usage looks like this:</p>
<pre><code class="language-ts">const palindrome = new Palindrome('())(');
console.log(palindrome); // Output: Palindrome { value: '())(' }
console.log(palindrome.value); // Output: '())('

const invalidPalindrome = new Palindrome('(())');
// Error: &quot;(())&quot; is not a palindrome
</code></pre>
<p>The <code>Palindrome</code> class guarantees that every instance of <code>Palindrome</code> contains a string that has passed the constructor validation. If you have any functions that <em>must</em> have a palindrome, the <code>Palindrome</code> type is an effective way to enforce it.</p>
<p>If you would rather not throw an error, but check if the string is a palindrome and handle the invalid case another way, you can create a parse method that wraps the palindrome creation in a <code>try</code> block, and return <code>undefined</code> if it fails:</p>
<pre><code class="language-ts">class Palindrome {
    // ...

    static parse (value: string): Palindrome | undefined {
        try {
            return new Palindrome(value);
        } catch (error) {
            return error;
        }
    }
}

console.log(Palindrome.parse('())(')); // Output: Palindrome { value: '())(' }
console.log(Palindrome.parse('(())')); // Output: undefined
</code></pre>
<h2 id="a-sorted-array">A sorted array</h2>
<p>A constructor does not have to throw errors to ensure a constraint. It can also do the work to transform data to a desired form, then pin it in place.</p>
<p>For instance, you can create a <code>SortedArray</code> class that sorts your array for you:</p>
<pre><code class="language-ts">class SortedArray&lt;T&gt; {
    // Mark as ReadonlyArray to ensure contents stay sorted
    readonly contents: ReadonlyArray&lt;T&gt;;

    constructor (contents: T[]) {
        // Copy the array so we do not reorder the original array,
        // and prevent changes to the original array from affecting our sorted array
        const copy = [...contents];
        copy.sort();
        this.contents = copy;
    }
}

const sortedArray = new SortedArray([0, 5, 3, 4, 4, 2]);
console.log(sortedArray.contents); // Output: [ 0, 2, 3, 4, 4, 5 ]
</code></pre>
<p>This may be useful if you are working with algorithms that expect a sorted array, like search.</p>
<h2 id="a-range-with-an-estimate">A range with an estimate</h2>
<p>Classes can, of course, also enforce constraints for multiple values. While I was experimenting with a game-playing traditional AI, my search algorithm used an <code>EstimateRange</code> data type to describe the minimum, estimate, and maximum value of a given game state. To make sense, the minimum cannot be greater than the maximum, and the estimate must be between them.</p>
<p>Here is how this can be enforced in TypeScript:</p>
<pre><code class="language-ts">class EstimateRange {
    readonly minimum: number;
    readonly estimate: number;
    readonly maximum: number;

    constructor (minimum: number, estimate: number, maximum: number) {
        if (minimum &gt; maximum) {
            throw new Error(`Minimum (${minimum}) is greater than maximum (${maximum})`);
        } else if (estimate &gt; maximum) {
            throw new Error(`Estimate (${estimate}) is greater than maximum (${maximum})`);
        } else if (estimate &lt; minimum) {
            throw new Error(`Estimate (${estimate}) is less than minimum (${minimum})`);
        }

        this.minimum = minimum;
        this.estimate = estimate;
        this.maximum = maximum;
    }
}

console.log(new EstimateRange(0, 7, 10));
// Output: EstimateRange { minimum: 0, estimate: 7, maximum: 10 }

console.log(new EstimateRange(10, 7, 0));
// Error: Minimum (10) is greater than maximum (0)
</code></pre>
<p>The point I am trying to make with the variety of examples is that there is a lot you can do with classes. The constraints you can enforce are mostly limited by your imagination.</p>
<h2 id="a-warning">A warning</h2>
<p>This trick comes with a caveat: <strong>If possible, you are better off enforcing constraints with simpler alternatives.</strong> I prefer using more concise type system features when I can. For TypeScript, you can browse the <a href="https://www.typescriptlang.org/docs/handbook/2/everyday-types.html">Everyday Types</a>, <a href="https://www.typescriptlang.org/docs/handbook/2/objects.html">Object Types</a> and <a href="https://www.typescriptlang.org/docs/handbook/2/types-from-types.html">Creating Types from Types</a> pages of the TypeScript handbook for inspiration.</p>
<p>When simpler alternatives for type checks are insufficient, class constructor validation is a powerful alternative to fall back on.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Using TypeScript to prevent common mistakes</title>
      <link>https://www.cvennevik.no/post/using-typescript-to-prevent-common-mistakes/</link>
      <pubDate>Tue, 17 Jan 2023 00:43:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/using-typescript-to-prevent-common-mistakes/</guid>
      <description><![CDATA[<p>A partial answer to what I like about static type systems.</p>
]]></description>
      <content:encoded><![CDATA[<p>I have been struggling to write an article about type systems for about a week now. The ideas and angles I want to take kept changing between each writing session, preventing me from ever completing a single coherent article.</p>
<p>After venting about this on Mastodon, another user asked me what I thought about static types. They were mostly experienced with dynamically typed languages, and prefer the flexibility they offer.</p>
<p>It turns out this question was all I needed to focus and get my writing back on track - you may take this blog post as my longform answer.</p>
<p>In short: I think static types are a useful tool to prevent us from making very common mistakes. Like, really common. Like &quot;half of the bugs I investigate in JavaScript applications are caused by this&quot; common.</p>
<p>Here's a few examples to illustrate the types of mistakes I'm talking about, and how adding static types with TypeScript helps prevent them.</p>
<h2 id="mistake-%231%3A-accessing-undefined-property-names">Mistake #1: Accessing undefined property names</h2>
<p>Say we are working with an object containing user profile data, and we want to send an email to that user. To do this, we access the user's email address via <code>user.emailAddress</code> and pass it to <code>sendEmail</code>.</p>
<pre><code class="language-ts">function sendEmailToUser (user) {
    sendEmail(user.emailAddress);
}
</code></pre>
<p>But what if we are mistaken? What if the <code>user</code> object's property is actually named <code>emailaddress</code>, or <code>address</code>, or <code>username</code>, or - gasp - it does not actually have a property for email address at all? Well, then this code will instead attempt to send an email to <code>undefined</code>. That's no good.</p>
<p>To check for this potential issue, let us say we found the <code>UserProfile</code> type that describes the user data we expect, and specify that <code>user</code> is of type <code>UserProfile</code>.</p>
<pre><code class="language-ts">interface UserProfile {
    // ...
    contactInfo: {
        // ...
        emailAddress: string
    }
}

function sendEmailToUser (user: UserProfile) {
    sendEmail(user.emailAddress); // Causes a build error!
}
</code></pre>
<p>Oops! It turns out the <code>user.emailAddress</code> property does not exist. Now, because we are trying to access a property that does not exist on <code>UserProfile</code>, the TypeScript compiler produces an error.</p>
<p>The <code>UserProfile</code> type instead tells us that a <code>user.contactInfo.emailAddress</code> property exists. This is likely what we actually wanted to use, and replacing <code>user.emailAddress</code> with this will make the error go away.</p>
<h2 id="mistake-%232%3A-passing-invalid-data">Mistake #2: Passing invalid data</h2>
<p>Say we are working with a map, and want to place an icon at the spot where the user's mouse pointer is:</p>
<pre><code class="language-ts">function getMousePosition () {
    // ...
}

function setIconPosition (position) {
    // ...
}

function placeIconAtMousePosition () {
    const mousePosition = getMousePosition();
    setIconPosition(mousePosition);
}
</code></pre>
<p>What can go wrong here? Well, we do not know the structure of the data <code>getMousePosition</code> returns, nor what <code>setIconPosition</code> accepts. Even if we already know we are working with longitude and latitude positions in the same coordinate system, the position could be represented as a <code>{ lon, lat }</code> object, or an <code>{ x, y }</code> object, or a <code>[lon, lat]</code> array (or even a <code>[lat, lon]</code> array!).</p>
<p>Without type annotations, this code looks perfectly valid, even if the data structures may be incompatible. Now, if we add the correct types to the functions using TypeScript, the incompatibility comes to light:</p>
<pre><code class="language-ts">function getMousePosition (): { lon: number, lat: number } {
    // ...
}

function setIconPosition (position: { x: number, y: number }) {
    // ...
}

function placeIconAtMousePosition () {
    const mousePosition = getMousePosition();
    setIconPosition(mousePosition); // Causes a build error!
}
</code></pre>
<p>With the function types specified, TypeScript reports that we made a mistake passing <code>mousePosition</code> directly into <code>setIconPosition</code>. Instead, we should convert the <code>{ lon, lat }</code> object to an <code>{ x, y }</code> object.</p>
<pre><code class="language-ts">function placeIconAtMousePosition () {
    const mousePosition = getMousePosition();
    setIconPosition({
        x: mousePosition.lon,
        y: mousePosition.lat
    });
}
</code></pre>
<h2 id="mistake-%233%3A-not-handling-undefined-values">Mistake #3: Not handling undefined values</h2>
<p>The third common mistake TypeScript can prevent is the famed <em>&quot;billion dollar mistake&quot;</em>: <s>null</s> undefined values!</p>
<p>Let's reuse the map position code example and see what happens when we modify it. Say we change the implementation of <code>getMousePosition</code> so it returns <code>undefined</code> when the mouse is outside the map. TypeScript will not permit this since this does not match the return type of <code>getMousePosition</code>, so we change the return type so it can also be <code>undefined</code>:</p>
<pre><code class="language-ts">function getMousePosition (): { lon: number, lat: number } | undefined {
    // ...
}

function setIconPosition (position) {
    // ...
}

function placeIconAtMousePosition () {
    const mousePosition = getMousePosition();
    setIconPosition({
        x: mousePosition.lon, // Causes a build error!
        y: mousePosition.lat
    });
}
</code></pre>
<p>Oh no! This change actually breaks <code>placeIconAtMousePosition</code>, because it was written with the assumption that <code>getMousePosition</code> always returns a valid position. When it instead returns <code>undefined</code>, the code will throw a runtime error when trying to access <code>mousePosition.lon</code>.</p>
<p>If we were working with untyped JavaScript, this mistake may have managed to sneak in. Luckily, TypeScript caught this error for us. It refuses to compile until we have correctly handled the case where <code>mousePosition</code> is undefined. If we add a check for it, the error disappears:</p>
<pre><code class="language-ts">function placeIconAtMousePosition() {
    const mousePosition = getMousePosition();
    if (mousePosition === undefined) return;
    setIconPosition({
        x: mousePosition.lon,
        y: mousePosition.lat
    });
}
</code></pre>
<p>I like to set up development environments so it is easy to write correct code and hard to write incorrect code. Static types are only one of several tools I use for this, but they are one of my favorites. They tell us what we can and cannot do with our data, and they are effective for catching very common mistakes. Because of this, I find the overhead of opting into static typing with TypeScript well worth it.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Code reviews are overloaded</title>
      <link>https://www.cvennevik.no/post/code-reviews-are-overloaded/</link>
      <pubDate>Sat, 07 Jan 2023 22:55:00 +0000</pubDate>
      <guid>https://www.cvennevik.no/post/code-reviews-are-overloaded/</guid>
      <description><![CDATA[<p>On the pains of mandated code reviews, and how to reduce them.</p>
]]></description>
      <content:encoded><![CDATA[<h2 id="table-of-contents">Table of contents</h2>
<ul>
<li><a href="#code-reviews-are-effective">Code reviews are effective</a></li>
<li><a href="#branching-causes-problems">Branching causes problems</a></li>
<li><a href="#mandatory-code-reviews-encourage-long-lived-branches">Mandatory code reviews encourage long-lived branches</a></li>
<li><a href="#code-reviews-are-hard-to-replace">Code reviews are hard to replace</a></li>
<li><a href="#code-reviews-hurt-more-the-more-they-try-to-do">Code reviews hurt more the more they try to do</a></li>
<li><a href="#limit-your-code-reviews-to-the-most-important-concerns">Limit your code reviews to the most important concerns</a></li>
<li><a href="#this-is-a-suggested-experiment">This is a suggested experiment</a></li>
</ul>
<h2 id="code-reviews-are-effective">Code reviews are effective</h2>
<p><strong>Code reviews are effective for uncovering bugs.</strong> We have multiple large studies backing this claim, estimating that the bug-detection rate of code reviews is in the ballpark of 50%. This is better evidence than we have for most software development practices. From <a href="https://en.wikipedia.org/wiki/Code_review#Efficiency_and_effectiveness_of_reviews">the Wikipedia article on code review</a>:</p>
<blockquote>
<p>Capers Jones' ongoing analysis of over 12,000 software development projects showed that the latent defect discovery rate of formal inspection is in the 60-65% range. For informal inspection, the figure is less than 50%. The latent defect discovery rate for most forms of testing is about 30%. A code review case study published in the book Best Kept Secrets of Peer Code Review found that lightweight reviews can uncover as many bugs as formal reviews, but were faster and more cost-effective in contradiction to the study done by Capers Jones.</p>
</blockquote>
<p>In addition to their primary value in discovering bugs, they can also be used to assess and improve many other aspects of the code. Design, readability, maintainability, code quality, test quality and coverage, consistency with project style guidelines and documentation are all areas where reviewers can find issues and suggest improvements. The act of reviewing and giving feedback can even help transfer knowledge between developers and be a tool for mentoring and learning.</p>
<p>On account of these benefits, code reviews have become wildly popular, and most software projects mandate that all changes must be approved by one or more reviewers. This virtually always means a <em>pull request based workflow</em>, where developers branch out from mainline, make some changes, then open a pull request that requires approval from a reviewer to merge back into mainline. At time of writing, this is the predominant way of working in our industry.</p>
<h2 id="branching-causes-problems">Branching causes problems</h2>
<p>In projects using pull requests, the most popular strategy for branching is <em>feature branching</em>, creating a branch for a single feature and opening a pull request when the feature is complete. This is a convenient and intuitive way of organizing changes. However, these feature branches tend to be long-lived (on the order of days or weeks), and long-lived branches cause some serious issues.</p>
<p>In part four of Thierry de Pauw's article series <a href="https://thinkinglabs.io/articles/2021/04/26/on-the-evilness-of-feature-branching.html">On the Evilness of Feature Branching</a>, he goes into <a href="https://thinkinglabs.io/articles/2022/05/30/on-the-evilness-of-feature-branching-the-problems.html">the problems</a> of feature branching. The article is worth reading in full, but to summarize some of its points:</p>
<ul>
<li><strong>It delays feedback</strong> on how well changes integrate with other team members' work and how it runs in production.</li>
<li><strong>It causes rework</strong> through merge conflicts.</li>
<li><strong>It discourages refactoring</strong> as they have a high risk of causing merge conflicts.</li>
<li><strong>It introduces batch work and inventory</strong>, trapping valuable work in the system and worsening the throughput, quality, stability and lead time of changes.</li>
<li><strong>It increases risks</strong> by batching changes into large sets which are more likely to break, and harder to find the cause of when they do.</li>
</ul>
<p>Key to these issues is that they are more frequent and more severe the longer the branches live and the larger the changes are. Conversely, shorter-lived branches and smaller changes cause less issues. We can nearly eliminate the branching issues by pushing this all the way to <a href="https://martinfowler.com/articles/branching-patterns.html#continuous-integration">continuous integration</a>, where everyone's work is merged into mainline every day, potentially even multiple times an hour.</p>
<p>Code reviews make this infeasible for most software teams.</p>
<h2 id="mandatory-code-reviews-encourage-long-lived-branches">Mandatory code reviews encourage long-lived branches</h2>
<p>When merging your work requires another developer to review and approve it, merging <em>will</em> happen less frequently, and pull requests <em>will not</em> shrink beyond a certain size. Dragan Stepanović explains this best in his article <a href="https://www.infoq.com/articles/co-creation-patterns-software-development/">From Async Code Reviews to Co-Creation Patterns</a>.</p>
<p>In short, code reviews introduce long wait times to the integration process. First, after a pull request is opened, the author waits for a review. Then, if the reviewer discovers any issues they think the author should handle, the reviewer waits for the author to respond to the feedback. This cycle repeats some number of times until the reviewer is satisfied and approves the pull request.</p>
<p>These wait times encourage developers to start new work in the meanwhile (increasing work-in-progress), and to batch their changes into larger pull requests. This, again, makes each review take longer, making it harder for developers to find time to review them, and increasing the odds of multiple rounds of review - increasing wait times even more! This vicious cycle results in pull requests often taking multiple days before they are able to be merged.</p>
<p>If a team still tries to make a push for continuous integration in this environment, they are fighting against the stream. The more frequently team members try to integrate, the more often they have to interrupt each other to review and respond to reviews. Developer attention bounces between multiple tasks, flow efficiency (time spent <em>working</em> to time spent <em>waiting</em>) plummets, and productivity drops. Every team will hit a point where the pain of this is too high and will stop integrating their changes any more frequently - typically stopping well short of continuous integration.</p>
<h2 id="code-reviews-are-hard-to-replace">Code reviews are hard to replace</h2>
<p>Many developers who recognize these problems assert that this kind of code review is a net negative and should be done away with altogether. Dave Farley, co-author of <em>Continuous Delivery</em>, insists that <a href="https://www.davefarley.net/?p=247">you are better off not branching at all</a>:</p>
<blockquote>
<ul>
<li>Don't Branch!</li>
<li>Don't Branch!</li>
<li>Don't Branch!</li>
</ul>
</blockquote>
<p>Instead of doing after-the-fact code review, he and others recommend that you support the quality of your software through other practices. The top recommendations are pair programming and mob/ensemble programming, which function as a sort of continuous code review while boosting the flow of work and knowledge sharing within your team. Test-driven development and a &quot;<em><a href="https://www.jamesshore.com/v2/books/aoad2/no_bugs">No Bugs</a></em>&quot;, root-cause eliminating attitude help reduce bug rates even further. By employing these practices, you may achieve better results than relying on code reviews. And I <em>want</em> to believe this.</p>
<p>However, in teams that frequently catch serious errors in code review, <strong>this is hard to sell</strong>. Most developers do not use these alternative practices, and asking people to change the way they work and spend time practicing new skills is a big ask for most teams. Without these changes, slashing code review will in all likelihood lead to more defects being pushed to mainline and escaping to production. Software teams have very reasonable motives for not wanting to do this.</p>
<p>This leaves me conflicted. I cannot in good conscience say that most teams should drop mandatory code reviews and that this will not cause major issues. Yet, I am thoroughly convinced that continuous integration <em>is</em> a better way of working.</p>
<p>Trapped in the middle, I am here to suggest a compromise: <strong>Code reviews should be reduced to their bare essentials.</strong></p>
<h2 id="code-reviews-hurt-more-the-more-they-try-to-do">Code reviews hurt more the more they try to do</h2>
<p>Here is my line of reasoning:</p>
<ol>
<li>When you look for more things in a code review, it becomes more demanding and time-consuming.</li>
<li>When code reviews get harder, developers will put them off, and wait times will grow.</li>
<li>When wait times grow, branches will live longer and pull requests will get larger, feeding the cycle and causing integration pain.</li>
</ol>
<p><strong>Conclusion:</strong> <em>The more things you look for in a code review, the more you will experience integration pain.</em> Conversely, if you reduce the number of things you look for in a code review, you will be able to integrate your work more frequently. If review gets easy enough, you may even find continuous integration feasible!</p>
<p>With this in mind, it becomes clear that we have made the review process very hard for ourselves. The most common thing to do is to include <em>every possible thing</em> worth having an opinion on in the scope of review. For instance, take <a href="https://google.github.io/eng-practices/review/reviewer/looking-for.html#summary">Google's sumary of what a reviewer should look for</a>:</p>
<blockquote>
<p>In doing a code review, you should make sure that:</p>
<ul>
<li>The code is well-designed.</li>
<li>The functionality is good for the users of the code.</li>
<li>Any UI changes are sensible and look good.</li>
<li>Any parallel programming is done safely.</li>
<li>The code isn’t more complex than it needs to be.</li>
<li>The developer isn’t implementing things they might need in the future but don’t know they need now.</li>
<li>Code has appropriate unit tests.</li>
<li>Tests are well-designed.</li>
<li>The developer used clear names for everything.</li>
<li>Comments are clear and useful, and mostly explain why instead of what.</li>
<li>Code is appropriately documented (generally in g3doc).</li>
<li>The code conforms to our style guides.</li>
</ul>
</blockquote>
<p><strong>This is a lot!</strong> A lot of things to pay attention to while reviewing, a lot to write feedback on, a lot of comments for the author to respond to. Several concerns like code quality and design (and without an authoritative style guide, code style and formatting) are highly subjective, and have a higher chance of causing disagreements, discussions, and multiple rounds of review - skyrocketing wait times.</p>
<p>Not only does this bucket list of concerns make review harder, but discussions of fuzzier, less critical issues drown out discussion of bugs. Quoting <a href="https://en.wikipedia.org/wiki/Code_review#Efficiency_and_effectiveness_of_reviews">the Wikipedia article</a> again:</p>
<blockquote>
<p>Empirical studies provided evidence that up to 75% of code review defects affect software evolvability/maintainability rather than functionality [...] This also means that less than 15% of the issues discussed in code reviews are related to bugs.</p>
</blockquote>
<p>Despite our primary motivation for mandating code review being bug reduction, we spend the majority of our attention on other, less critical issues. Combining this diluted focus with its influence to make pull requests larger, it is likely that trying to improve more things with code review actually makes matters worse.</p>
<h2 id="limit-your-code-reviews-to-the-most-important-concerns">Limit your code reviews to the most important concerns</h2>
<p>Since mandatory code reviews cause more issues the more concerns they look for, they should be stripped down to the bare minimum of concerns that must be improved before merge. This will reduce the costs of review while improving its effectiveness for the concerns you do look for. What this bare minimum set is may vary from project to project, and you are free to decide what this is for yourself.</p>
<p><strong>Personally, I am convinced that you should cut any concern from your list that is not externally visible and can be improved later.</strong> This includes:</p>
<ul>
<li>Formatting and code style</li>
<li>Code quality and internal design details</li>
<li>Comments and documentation</li>
<li>Test coverage and quality</li>
</ul>
<p>All of these things are (more or less) valuable, and we want to do them well. However, <strong>none of them are externally visible</strong>, meaning it does not matter to our users if we merge and deploy them to production. Additionally, <strong>all of them can be improved later</strong>, and frequent low-friction integration makes it <em>easier</em> to make such improvements. Including them in review would harm integration frequency, which makes it harder to improve the quality of our codebase when we discover these issues while working.</p>
<p>If a developer opens pull requests that aren't up to snuff on any of these points, you have a couple of alternatives instead of checking it during review:</p>
<ol>
<li><strong>Talk to the developer about it.</strong> Make sure you agree to a common set of standards, and that they have the environment and resources to learn how to fulfill them. This is a longer term solution that will save you frustration in the long run.</li>
<li><strong>Fix it yourself.</strong> If you see room for improvement beyond your team's common set of standards, do it yourself instead of asking the author to do it. It is more effective and efficient, and it contributes to your team's sense of collective code ownership - you all have the right and responsibility to make improvements when you see them. And, since this change is to an issue that should be ignored by reviewers, it should be quick and easy to approve and merge back into mainline.</li>
</ol>
<p>Conversely, changes that are externally visible, or cannot be improved later, are more worth reviewing:</p>
<ul>
<li><strong>Bugs and security issues.</strong> We should ideally never introduce any of these, and we want to minimize the chance of any of them escaping to production.</li>
<li><strong>Design decisions that are hard to undo.</strong> This includes both external API designs (which are very hard to change once they are public), user interface designs, and any changes to functionality. The cost of getting these wrong is high, so it is worth spending extra effort getting them right.</li>
</ul>
<p>By limiting your review scope to these core concerns, you minimize the cost of mandating code reviews, while maintaining quality control on the issues you care the most about.</p>
<p><em>(Limiting and focusing the objective of code review like this also makes it easier to see when code reviews become obsolete - when bug rates drop to acceptable levels pre-review, and when you discuss and refine your irreversible design decisions outside of review. It is very easy to imagine high-performing teams working like this.)</em></p>
<h2 id="this-is-a-suggested-experiment">This is a suggested experiment</h2>
<p>While this strategy of cutting the scope of review makes a lot of sense to me, I cannot predict how it will play out for you, in your team, in your circumstances. I do not know to what degree it will make reviews easier and reduce integration pain, and I do not know what unexpected side effects it will have.</p>
<p>What I do believe is that this experiment is low risk, it is not very disruptive, and the potential rewards are great enough that <strong>you should try it out</strong>. Talk it out with your team, find a scope of review to try, trial it for a week or two, then reflect on how it went. If you do not like the results, you can always go back to your old way of working afterwards.</p>
<p><strong>If you try this, or have already tried it, please message me to share your experience!</strong> Contact me on Mastodon at <a href="https://hachyderm.io/@cvennevik">@cvennevik@hachyderm.io</a> (so I can share it further, if you like!), or email me at <a href="mailto:cvennevik@gmail.com">cvennevik@gmail.com</a>.</p>
<p><em>Edit, April 14th 2023: <a href="https://www.cvennevik.no/post/oops-i-made-code-review-painful/">I wrote a post describing my experience following this idea.</a></em></p>
]]></content:encoded>
    </item>
    
  </channel>
</rss>